{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "backtesting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB_OAFMojLU9"
      },
      "source": [
        "# Backtesting of VaR Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8mW1GxXbYOx"
      },
      "source": [
        "%%capture\n",
        "# Installing Yfinance package used to download data\n",
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "import yfinance as yf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# vargan_model.ipynb does the pretraining of the GAN, we need to import some things for additional training and backtesting.\n",
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "metadata": {
        "id": "-aiXGSFdBjmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If running on Google colab, to give acces to the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks"
      ],
      "metadata": {
        "id": "OlDKeKIWCOj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikpKR_ktkaWP"
      },
      "source": [
        "%%capture\n",
        "\n",
        "import tensorflow as tf\n",
        "#import yfinance as yf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st \n",
        "#import dataPrepFunc as dp\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "from vargan_model import WGAN, mean_tot, std_tot, to_stock_M, get_returns, generator_loss, discriminator_loss, varGan_sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the backtesting data as was done for the data used for pretraining the model\n",
        "data_back_test = yf.download(\"HM-B.ST EKTA-B.ST TEL2-B.ST SEB-A.ST INVE-B.ST\", start=\"2009-12-21\", end=\"2020-01-01\")\n",
        "data_back_test = data_back_test['Adj Close']\n",
        "# Impute with previous valid value if there is missing data \n",
        "data_test=data_back_test.fillna(method='ffill')\n",
        "# Make into numpy array\n",
        "data_test = data_test.to_numpy()\n",
        "data_test = get_returns(data_test)\n",
        "data_test_gan = to_stock_M(data_test, 1).astype(\"float32\")"
      ],
      "metadata": {
        "id": "qbXAXewAzKEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuPGAEWWjYNh"
      },
      "source": [
        "## 1. Unconditional VaR Estimation with GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iWAQRiljKKG"
      },
      "source": [
        "# load the pretrained GAN\n",
        "generator_uncon = tf.keras.models.load_model('generator_pretrained.h5')\n",
        "discriminator_uncon = tf.keras.models.load_model('discriminator_pretrained.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjmTdhmQk0yY"
      },
      "source": [
        "# optimezers to use, for additional training\n",
        "generator_optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=0.00002, beta_1=0.5, beta_2=0.9\n",
        ")\n",
        "\n",
        "discriminator_optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=0.00002, beta_1=0.5, beta_2=0.9\n",
        ")\n",
        "\n",
        "k=5\n",
        "noise_dim = 2*k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cccejSIjla06"
      },
      "source": [
        "# Function to calculate VaR estimates over a test period \n",
        "# we train it for additional 100 epoch on  the 252 most recent days\n",
        "# and use this estimate for 5 days\n",
        "\n",
        "def VaR_est(test_data, generator=generator_uncon, discriminator=discriminator_uncon, update_freq = 5, additional_epochs = 100, b_window = 252):\n",
        "    \n",
        "    # list to store var estimates over testing period\n",
        "    \n",
        "    var_estimates =[]\n",
        "    \n",
        "    nbr_days_to_predict = test_data.shape[0]-b_window\n",
        "    nbr_estimates = (nbr_days_to_predict)/update_freq\n",
        "    nbr_estimates = int(np.ceil(nbr_estimates))\n",
        "    \n",
        "    for i in range(nbr_estimates):\n",
        "        start_recent=i*update_freq\n",
        "        end_recent=start_recent + b_window\n",
        "        data_recent = test_data[start_recent:end_recent,:,:]\n",
        "        # Now we train the generator for additional epochs\n",
        "        discriminator_up = discriminator\n",
        "        generator_up = generator\n",
        "        wgan_up = WGAN(\n",
        "        discriminator = discriminator_up,\n",
        "        generator = generator_up,\n",
        "        latent_dim=noise_dim,\n",
        "        disc_extra_steps=5,)\n",
        "        # Compile \n",
        "        wgan_up.compile(\n",
        "        d_optimizer=discriminator_optimizer,\n",
        "        g_optimizer=generator_optimizer,\n",
        "        g_loss_fn=generator_loss,\n",
        "        d_loss_fn=discriminator_loss)\n",
        "        # Continue training \n",
        "        varGan_up = wgan_up.fit(data_recent, batch_size = 36, epochs = additional_epochs, verbose = 0)\n",
        "        # Use updated model to estimate VaR \n",
        "        var_val = varGan_sim(generator=generator_up)\n",
        "        # The estimate is the same for update_freq nbr of days\n",
        "        nbr_new_estimates = np.min([update_freq, nbr_days_to_predict-start_recent])\n",
        "        for a in range(nbr_new_estimates):\n",
        "            var_estimates.append(var_val)\n",
        "        print(f'VaR estimates for days {i*update_freq +1} --> {(i+1)*update_freq} done') \n",
        "            \n",
        "    return var_estimates            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHbfnl7hoevt"
      },
      "source": [
        "# VaR estimates for the test data\n",
        "estimated_var = VaR_est(data_test_gan, update_freq= 5, additional_epochs = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80j5QxMCN32h"
      },
      "source": [
        "VaR_uncon = np.array(estimated_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47UEb5BX1gX"
      },
      "source": [
        "## 2. Variance Covariance Method Based on 252 Most Recent Returns  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O29bypgXg3a"
      },
      "source": [
        "def vcv_Var(data, k = 5, alfa = 0.05, obs_b = 252):\n",
        "    data_length = data.shape[0]\n",
        "    p_w = 1/k\n",
        "    portfolio_weights = p_w * np.ones((k,1))\n",
        "    # List to store var values in\n",
        "    VaR_list = []\n",
        "    for i in range(0, data_length-obs_b):\n",
        "        start = i\n",
        "        end = obs_b + i\n",
        "        est_data = data[start:end,]\n",
        "        # Portfolio return\n",
        "        mu_hat = np.mean(est_data, axis = 0)\n",
        "        p_mu = np.matmul(portfolio_weights.transpose(), mu_hat)\n",
        "        # Sample covariance matrix\n",
        "        cov_hat = np.cov(est_data, rowvar = False)\n",
        "        # Calculate portfolio variance\n",
        "        a = np.matmul(portfolio_weights.transpose(), cov_hat)\n",
        "        p_variance = np.matmul(a, portfolio_weights)\n",
        "        # z-score \n",
        "        z = st.norm.ppf(1-alfa)\n",
        "        # VaR\n",
        "        VaR = -(p_mu - ( z*np.sqrt(p_variance)))\n",
        "        VaR_list.append(VaR)   \n",
        "    return VaR_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDPQPULquP7T"
      },
      "source": [
        "var_list = vcv_Var(data_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrrYsebIwVQp"
      },
      "source": [
        "VaR_vcv = np.array(var_list).reshape((len(var_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrIHDjnj3_4N"
      },
      "source": [
        "## 3. Plotting VaR Estimates Against the Acctual Returns \n",
        "\n",
        "For a good model we expect about 5% of the returns to be below the returns given by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfpQWcwH6UDb"
      },
      "source": [
        "# The acctual returns, for backtesting, note first 252 used for estimation\n",
        "start_back_test = data_test.shape[0] - 252\n",
        "actual_returns = data_test[-start_back_test:,:]\n",
        "\n",
        "# period for back test\n",
        "b_period =data_back_test.index\n",
        "b_period = b_period.to_numpy()\n",
        "b_period = b_period[253:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQutI8XC92Zx"
      },
      "source": [
        "# Calculate acctual returns for the equaly weighted portfolio\n",
        "def portfolio_returns(data, k=5):\n",
        "  days = data.shape[0]\n",
        "  p_w = 1/k\n",
        "  portfolio_weights = p_w * np.ones((k,1))\n",
        "  p_returns = []\n",
        "  for row in range(days):\n",
        "    returns = data[row,:]\n",
        "    p_r = np.matmul(portfolio_weights.transpose(), returns)\n",
        "    p_returns.append(p_r)\n",
        "  p_returns = np.array(p_returns).reshape((days))\n",
        "  return p_returns     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51DOjhlFAMww"
      },
      "source": [
        "actual_returns_p = portfolio_returns(actual_returns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_2jhbTOgisu"
      },
      "source": [
        "#  VaR estimates of WGAN-GP model against accual returns\n",
        "plt.plot_date(b_period, VaR_uncon, ls=\"solid\", marker =\"None\", label = \"Unconditional GAN (model 2)\")\n",
        "plt.plot_date(b_period, actual_returns_p, label = \"Actual portfolio returns\", markersize=1, color = \"green\")\n",
        "plt.legend(loc=\"upper left\", fontsize=\"small\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Return\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpTMgmVgaC46"
      },
      "source": [
        "# VCV model VS acctual returns \n",
        "plt.plot_date(b_period, -VaR_vcv, ls=\"solid\", marker =\"None\", label = \"Variance covariance (model 6)\")\n",
        "plt.plot_date(b_period, actual_returns_p, label = \"Actual portfolio returns\", markersize=1, color = \"green\")\n",
        "plt.legend(loc=\"upper left\", fontsize=\"small\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Return\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}